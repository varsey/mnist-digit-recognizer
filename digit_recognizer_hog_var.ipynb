{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","version":"3.7.7"},"notebookId":"05d39842-67d6-4735-9a49-f493c9640dea"},"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nimport tensorflow as tf\nfrom skimage.feature import hog","metadata":{"cellId":"rsps4jt8yndkp8whxoknrg","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# loading data\ntrain = pd.read_csv(\"train.csv\")\ntest = pd.read_csv(\"test.csv\")","metadata":{"cellId":"kngv6cliqar5d11doz6yq","trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# data pre-processing\ny_train = train['label'].astype('float32')\nX_train = train.drop(['label'], axis=1).astype('int32')\nX_test = test.astype('float32')\nX_train.shape, y_train.shape, X_test.shape","metadata":{"cellId":"13pa7lnxurvka4ysmppyuil","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"((42000, 784), (42000,), (28000, 784))"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# data pre-processing - reshaping (The first number is the number of images, Then comes the shape of each image (28x28). The last number is 1, which signifies that the images are greyscale.)\nX_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)\nX_train.shape, X_test.shape","metadata":{"cellId":"t3ileqlyoz478aj98cy8b","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"((42000, 28, 28, 1), (28000, 28, 28, 1))"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"### Feature engineering using HOG: Histogram of Oriented Gradients","metadata":{"cellId":"r5eg0f8j1nlacdqeaq5gk"}},{"cell_type":"code","source":"X_train_feature = []\nfor i in range(len(X_train)):\n    feature = hog(X_train[i],orientations=9,pixels_per_cell=(14,14),cells_per_block=(1,1),block_norm=\"L2\")\n    X_train_feature.append(feature)\nX_train_feature = np.array(X_train_feature,dtype = np.float32)","metadata":{"cellId":"x3yf9hutsghmnntpsoktc","trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"X_test_feature = []\nfor i in range(len(X_test)):\n    feature = hog(X_test[i],orientations=9,pixels_per_cell=(14,14),cells_per_block=(1,1),block_norm=\"L2\")\n    X_test_feature.append(feature)\nX_test_feature = np.array(X_test_feature,dtype=np.float32)","metadata":{"cellId":"qzxhzz2b67c5cnokmtwt4a","trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# data normalization - dimensionality reduction\n# dataset has images with pixel values in the range [0, 255] - for the [0,1] scaling, you simply divide by 255\n#X_train = X_train/255.0\n#X_test = X_test/255.0","metadata":{"cellId":"urxoo03ic8h965awlzevm","trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"X_train_feature = X_train/255.0\nX_test_feature = X_test/255.0","metadata":{"cellId":"ym5sbmw8jq7xgtsd5ghj2","trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#count images by label\nsns.countplot(x='label', data=train);","metadata":{"cellId":"dkla9jfa6rautjeqphxgnm","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"cellId":"v5mmhsee8gu39toykyxn8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# one-hot encoding - create a column for each output category and a binary variable is inputted for each category\nfrom keras.utils.np_utils import to_categorical\ny_train = to_categorical(y_train, num_classes = 10)\ny_train.shape","metadata":{"cellId":"2791u7uilo3iyugsxa3dj5f","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"(42000, 10)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# plot the first image in the dataset\nplt.imshow(X_train[0])","metadata":{"cellId":"q45j7m8q8ch9oe7g4cygk","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f11815d2310>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAM90lEQVR4nO3dYYxc5XXG8eexvdiKDY03wOIaN1BqVbIqxUQrJw0opUFBgBSZSCmKGyGnQtmoiVWTpiqIfgj9RgmEJm1D5BQXJ0qgUQPClawkrouKUhBi7bi2wSlQxyjeGm/BHzAhsdf26Ye9RAvsvLPM3Jk79vn/pNHM3DN37tHIj9+Z+87s64gQgLPfvKYbANAfhB1IgrADSRB2IAnCDiSxoJ8HO8cLY5EW9/OQQCq/0i90Io57tlpXYbd9raSvSpov6R8j4s7S4xdpsT7gq7s5JICCp2JHy1rHb+Ntz5f0D5Kuk7RK0jrbqzp9PgC91c1n9jWSXoiIAxFxQtJDktbW0xaAunUT9uWSfj7j/qFq25vYHrM9bnt8Sse7OByAbvT8bHxEbIqI0YgYHdLCXh8OQAvdhH1C0ooZ9y+utgEYQN2E/WlJK21favscSZ+UtLWetgDUreOpt4g4aXuDpB9qeuptc0Q8U1tnAGrV1Tx7RGyTtK2mXgD0EF+XBZIg7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJvi7ZDPTT0v8cbll76NJ/L+77vr/5XLF+0Vef6KinJjGyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASzLPjjDXy5HnF+tdXtF5geCqGivs6OmppoHUVdtsHJR2TdErSyYgYraMpAPWrY2T/w4h4uYbnAdBDfGYHkug27CHpR7Z32h6b7QG2x2yP2x6f0vEuDwegU92+jb8yIiZsXyhpu+2fRsTjMx8QEZskbZKk8zx8Fp72AM4MXY3sETFRXU9KekTSmjqaAlC/jsNue7Htc9+4LekaSfvqagxAvbp5Gz8i6RHbbzzPdyPiB7V0BUg6cNfvF+sPXXxPsb7QC1vWPrhrXXHf33ygPG6dKlYHU8dhj4gDkt5XYy8AeoipNyAJwg4kQdiBJAg7kARhB5LgJ65ozNE/KU+tPbnu7mJ9ybxFxfqXX1nVsjby6fJvt069+mqxfiZiZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJJhnR0/N/93faVlb+4XHivv+Rpt59D0nyj80ffTuj7SsvfuVJ4v7no0Y2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCebZ0ZWpa8oL937knv9oWfvz4Z92dezP3LWxWL/gW/nm0ksY2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCebZUXTkzz5UrO+89e+L9dOKlrXnpk4U97352ZuK9WWPHCjWTxar+bQd2W1vtj1pe9+MbcO2t9t+vrpe2ts2AXRrLm/jH5B07Vu23SZpR0SslLSjug9ggLUNe0Q8LunoWzavlbSlur1F0g31tgWgbp1+Zh+JiMPV7ZckjbR6oO0xSWOStEjv6vBwALrV9dn4iAip9VmYiNgUEaMRMTqkhd0eDkCHOg37EdvLJKm6nqyvJQC90GnYt0paX91eL+nRetoB0CttP7PbflDSVZLOt31I0pck3Snpe7ZvlvSipBt72SR6Z8Elv1Wsf2rshz079h+Nf6ZYX/GJfcU68+jvTNuwR8S6FqWra+4FQA/xdVkgCcIOJEHYgSQIO5AEYQeS4CeuZ7n5IxcW6x/+1/3F+i1Ln2tzBBerPzv5q5a1xdvObfPcqBMjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTz72e68JcVyt8smt3PL+z/Wsjb8Cksq9xMjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTz7WWDBxctb1tb8S3kefV6b36O384XDHyjW45etf8+O/mJkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkmGc/C0x+Y3HL2u3n7y3ue7rNc2/83yuK9Z/9QXm8OP36622OgH5pO7Lb3mx70va+GdvusD1he3d1ub63bQLo1lzexj8g6dpZtt8bEaury7Z62wJQt7Zhj4jHJR3tQy8AeqibE3QbbO+p3uYvbfUg22O2x22PT+l4F4cD0I1Ow36fpMskrZZ0WNI9rR4YEZsiYjQiRoe0sMPDAehWR2GPiCMRcSoiTkv6pqQ19bYFoG4dhd32shl3Py5pX6vHAhgMbefZbT8o6SpJ59s+JOlLkq6yvVpSSDoo6bO9axGl36tL0keXd/633187XT6PsvNrlxfr736dv/1+pmgb9ohYN8vm+3vQC4Ae4uuyQBKEHUiCsANJEHYgCcIOJMFPXAfAgveuKNbP/e4vivW/vvAnLWsvn/plcd/r7v7LYn3k208U6zhzMLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBLMsw+AF9eV59l/csnfdfzct06U//DvyNeYR8+CkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCevQ8mP/ehYv3hP/1ym2dYVKxumLiyZe2VTw23ee5X29RxtmBkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkmGevwfwLLijW/2LjPxfrly4oz6O3s+u+1S1rwwdYUhnT2o7stlfYfsz2s7afsb2x2j5se7vt56vrpb1vF0Cn5vI2/qSkL0bEKkkflPR526sk3SZpR0SslLSjug9gQLUNe0Qcjohd1e1jkvZLWi5praQt1cO2SLqhRz0CqME7+sxu+xJJl0t6StJIRByuSi9JGmmxz5ikMUlapHd13CiA7sz5bLztJZK+L+mWiHjTryciIiTFbPtFxKaIGI2I0SEt7KpZAJ2bU9htD2k66N+JiIerzUdsL6vqyyRN9qZFAHVo+zbetiXdL2l/RHxlRmmrpPWS7qyuH+1Jh2eAiT9eWazfuOQHPT3+ifPc0+fH2WEun9mvkHSTpL22d1fbbtd0yL9n+2ZJL0q6sScdAqhF27BHxI8ltRo6rq63HQC9wtdlgSQIO5AEYQeSIOxAEoQdSIKfuNZg3lS5PhWnivUhzy/Wj0f5AMcua/38FxX3RCaM7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBPPsNbjw608U6/+04bJiffG848X6vd/4RLG+8m/LxwckRnYgDcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJ59j7Yuuo9Xe1/kZhHR/cY2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgibZht73C9mO2n7X9jO2N1fY7bE/Y3l1dru99uwA6NZcv1ZyU9MWI2GX7XEk7bW+vavdGxN29aw9AXeayPvthSYer28ds75e0vNeNAajXO/rMbvsSSZdLeqratMH2HtubbS9tsc+Y7XHb41Mq//klAL0z57DbXiLp+5JuiYhXJd0n6TJJqzU98t8z234RsSkiRiNidEgLu+8YQEfmFHbbQ5oO+nci4mFJiogjEXEqIk5L+qakNb1rE0C35nI23pLul7Q/Ir4yY/uyGQ/7uKR99bcHoC5zORt/haSbJO21vbvadrukdbZXSwpJByV9tgf9AajJXM7G/1iSZyltq78dAL3CN+iAJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJOCL6dzD7/yS9OGPT+ZJe7lsD78yg9jaofUn01qk6e3tvRFwwW6GvYX/bwe3xiBhtrIGCQe1tUPuS6K1T/eqNt/FAEoQdSKLpsG9q+Pglg9rboPYl0Vun+tJbo5/ZAfRP0yM7gD4h7EASjYTd9rW2/9v2C7Zva6KHVmwftL23WoZ6vOFeNtuetL1vxrZh29ttP19dz7rGXkO9DcQy3oVlxht97Zpe/rzvn9ltz5f0nKSPSjok6WlJ6yLi2b420oLtg5JGI6LxL2DY/rCk1yR9KyJ+r9p2l6SjEXFn9R/l0oi4dUB6u0PSa00v412tVrRs5jLjkm6Q9Gk1+NoV+rpRfXjdmhjZ10h6ISIORMQJSQ9JWttAHwMvIh6XdPQtm9dK2lLd3qLpfyx916K3gRARhyNiV3X7mKQ3lhlv9LUr9NUXTYR9uaSfz7h/SIO13ntI+pHtnbbHmm5mFiMRcbi6/ZKkkSabmUXbZbz76S3LjA/Ma9fJ8ufd4gTd210ZEe+XdJ2kz1dvVwdSTH8GG6S50zkt490vsywz/mtNvnadLn/erSbCPiFpxYz7F1fbBkJETFTXk5Ie0eAtRX3kjRV0q+vJhvv5tUFaxnu2ZcY1AK9dk8ufNxH2pyWttH2p7XMkfVLS1gb6eBvbi6sTJ7K9WNI1GrylqLdKWl/dXi/p0QZ7eZNBWca71TLjavi1a3z584jo+0XS9Zo+I/8/kv6qiR5a9PXbkv6rujzTdG+SHtT027opTZ/buFnSeyTtkPS8pH+TNDxAvX1b0l5JezQdrGUN9Xalpt+i75G0u7pc3/RrV+irL68bX5cFkuAEHZAEYQeSIOxAEoQdSIKwA0kQdiAJwg4k8f8BjMtLROgJ0gAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}],"execution_count":121},{"cell_type":"code","source":"#check image shape\nX_train[0].shape","metadata":{"cellId":"ily01owjiaet2j9486uut8","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"(28, 28, 1)"},"metadata":{}}],"execution_count":122},{"cell_type":"code","source":"# splitting test and train datasets with 10% for test\n# from sklearn.model_selection import train_test_split\n# X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size = 0.1, random_state=42)","metadata":{"cellId":"xuqhafqzwwgfshbmcny509","trusted":true},"outputs":[],"execution_count":123},{"cell_type":"markdown","source":"## Building a Convolutional Neural Network (CNN) in Keras\n### Sequential model","metadata":{"cellId":"s7bubn9lu2kp3r59q5pfs"}},{"cell_type":"code","source":"# sequential allows you to build a model layer by layer.\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten\n#create model\nmodel = Sequential()\n#add model layers\nmodel.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\nmodel.add(Conv2D(32, kernel_size=3, activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))","metadata":{"cellId":"3n4bz7zoszkd9h8ek6u","trusted":true},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"* Our first 2 layers are Conv2D layers. These are convolution layers that will deal with our input images, which are seen as 2-dimensional matrices.\n* 64 in the first layer and 32 in the second layer are the number of nodes in each layer. This number can be adjusted to be higher or lower, depending on the size of the dataset. In our case, 64 and 32 work well, so we will stick with this for now.\n\n* Kernel size is the size of the filter matrix for our convolution. So a kernel size of 3 means we will have a 3x3 filter matrix. Refer back to the introduction and the first image for a refresher on this.\n\n* Activation is the activation function for the layer. The activation function we will be using for our first 2 layers is the ReLU, or Rectified Linear Activation. This activation function has been proven to work well in neural networks.\n\n* Our first layer also takes in an input shape. This is the shape of each input image, 28,28,1 as seen earlier on, with the 1 signifying that the images are greyscale.\n\n* In between the Conv2D layers and the dense layer, there is a ‘Flatten’ layer. Flatten serves as a connection between the convolution and dense layers.\n\n* ‘Dense’ is the layer type we will use in for our output layer. Dense is a standard layer type that is used in many cases for neural networks.\n\n* We will have 10 nodes in our output layer, one for each possible outcome (0–9).\n\n* The activation is ‘softmax’. Softmax makes the output sum up to 1 so the output can be interpreted as probabilities. The model will then make its prediction based on which option has the highest probability.","metadata":{"cellId":"wyjmlz1wngi2ztt6l240rb"}},{"cell_type":"code","source":"# compiling the model\n#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n# training the model, 7 epochs\n#model.fit(X_train, y_train, validation_data=(X_cv,y_cv), epochs=3)","metadata":{"cellId":"we2bzovecemp80werz606f","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Train on 42000 samples, validate on 4200 samples\nEpoch 1/3\n42000/42000 [==============================] - 53s 1ms/step - loss: 0.1499 - accuracy: 0.9550 - val_loss: 0.0551 - val_accuracy: 0.9833\nEpoch 2/3\n42000/42000 [==============================] - 53s 1ms/step - loss: 0.0518 - accuracy: 0.9840 - val_loss: 0.0255 - val_accuracy: 0.9933\nEpoch 3/3\n42000/42000 [==============================] - 51s 1ms/step - loss: 0.0323 - accuracy: 0.9894 - val_loss: 0.0165 - val_accuracy: 0.9952\n"},{"output_type":"display_data","data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f11200be650>"},"metadata":{}}],"execution_count":125},{"cell_type":"code","source":"# compiling the model with HOG\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n# training the model, 7 epochs\nmodel.fit(X_train_feature, y_train, epochs=3)","metadata":{"cellId":"7zfdvdrbomgaf0fhgcxf79","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/3\n42000/42000 [==============================] - 52s 1ms/step - loss: 0.1477 - accuracy: 0.9564\nEpoch 2/3\n42000/42000 [==============================] - 51s 1ms/step - loss: 0.0501 - accuracy: 0.9846\nEpoch 3/3\n42000/42000 [==============================] - 50s 1ms/step - loss: 0.0336 - accuracy: 0.9894\n"},{"output_type":"display_data","data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f10f564f5d0>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"* Adam is generally a good optimizer to use for many cases. The adam optimizer adjusts the learning rate throughout training.\n* The learning rate determines how fast the optimal weights for the model are calculated. \n* We will use ‘categorical_crossentropy’ for our loss function. This is the most common choice for classification. A lower score indicates that the model is performing better.\n* We will use the ‘accuracy’ metric to see the accuracy score on the validation set when we train the model.","metadata":{"cellId":"iq2ofvdjtqhczorw0pkysu"}},{"cell_type":"code","source":"# using our model to make predictions\ny_pred = model.predict(X_test_feature)\ny_pred = np.argmax(y_pred,axis=1)\n# saving submission for kaggle\nmy_submission = pd.DataFrame({'ImageId': list(range(1, len(y_pred)+1)), 'Label': y_pred})\nmy_submission.to_csv('submission.csv', index=False)","metadata":{"cellId":"1n6rmdgfw2cdbavv2jbk9b","trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Accuracy\n\nAdam optimizer 10 epochs : 0.98157","metadata":{"cellId":"stezsexrvqo6udwak7pq"}},{"cell_type":"markdown","source":"Adam optimizer 3 epochs: 0.98328","metadata":{"cellId":"0sm08qrncmthut2o7vjuo6"}},{"cell_type":"markdown","source":"HOG + Adam optimizer 3 epochs: 0.98471","metadata":{"cellId":"cph57ylzbbbqteqn2ns60r"}},{"cell_type":"markdown","source":"- USE TEST DS\n- Посмотреть точность с feature engeneering:","metadata":{"cellId":"gnabaj6lt1bykylnuqraw"}},{"cell_type":"markdown","source":"    HOG: Histogram of Oriented Gradients\n    SIFT: Scale Invariant Feature Transform\n    SURF: Speeded-Up Robust Feature\n","metadata":{"cellId":"wa5e76hhk6gwa54k0vy9a"}},{"cell_type":"code","source":"","metadata":{"cellId":"5metv96m4b9ot6p4gu7xa"},"outputs":[],"execution_count":null}]}